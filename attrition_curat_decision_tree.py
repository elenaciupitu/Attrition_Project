# -*- coding: utf-8 -*-
"""Attrition_curat_Decision_tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bGkHyLfcY6rykjLplOM3P7ydehn0hWQ6

### Import libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np
import seaborn as sns
from sklearn.ensemble import BaggingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import Normalizer, StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from IPython.display import display
pd.plotting.register_matplotlib_converters()
from pandas.plotting import register_matplotlib_converters

"""### Read dataset"""

df1 = pd.read_csv("./df1.csv")
df2 = pd.read_csv("./df2.csv")
attrition = pd.read_csv("./attrition.csv")

"""### Data preprocessing"""

indexes_df2 =  df2.loc[pd.isna(df2.Attrition) == True, "EmployeeNumber"]
indexes_attrition = attrition.loc[pd.isna(attrition.Attrition) == True, "EmployeeNumber"]

df2.dropna(inplace=True)
df1 = df1[df1["EmployeeNumber"].isin(indexes_df2) == False]

df1.drop(['EmployeeCount', 'DistanceFromHome'], axis=1, inplace=True)
df2.drop(['Over18', 'StandardHours'], axis=1, inplace=True)

# df1.drop("Age", axis=1, inplace=True)
# df2.drop("YearsInCurrentRole", axis=1, inplace=True)
# df2.drop("YearsSinceLastPromotion", axis=1, inplace=True)

"""##### Deleting outliers"""

df2 = df2[df2["YearsAtCompany"] < 60]
df2 = df2[df2['YearsWithCurrManager'] <= 17]
df2 = df2[df2['TotalWorkingYears'] <= 40]

# def repair(x):
#     if x > 500:
#         x = x / 360
#     return int(x)

# df2["TotalWorkingYears"] = df2["TotalWorkingYears"].apply(lambda x: repair(x))
# df2["YearsAtCompany"] = df2["YearsAtCompany"].apply(lambda x: repair(x))
# df2["YearsInCurrentRole"] = df2["YearsInCurrentRole"].apply(lambda x: repair(x))
# df2["YearsSinceLastPromotion"] = df2["YearsSinceLastPromotion"].apply(lambda x: repair(x))
# df2["YearsWithCurrManager"] = df2["YearsWithCurrManager"].apply(lambda x: repair(x))
# df1["Age"] = df1["Age"].apply(lambda x: repair(x))

"""### Categorical columns"""

df1['Department'] = df1['Department'].replace({
    'Research & Development': 0, 
    'Human Resources': 1, 
    'Sales': 2 })

df1['BusinessTravel'] = df1['BusinessTravel'].replace({
    'Non-Travel': 0, 
    'Travel_Rarely': 1, 
    'Travel_Frequently': 2 })

df1['EducationField'] = df1['EducationField'].replace({
    'Life Sciences': 0, 
    'Human Resources': 1,
    'Marketing': 2,
    'Medical': 3,
    'Technical Degree': 4,
    'Other': 5 })

df1['Gender'] = df1['Gender'].apply(lambda x: 1 if x == 'Female' else 0) 

df1['MaritalStatus'] = df1['MaritalStatus'].replace({
    'Divorced': 0, 
    'Single': 1, 
    'Married': 2 })


df2['Attrition'] = df2['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)

df2['OverTime'] = df2['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)

df1['JobRole'] = df1['JobRole'].astype('category').cat.codes

"""##### Split the dataframe into the train and test groups"""

X_test = df2[-400:]
X_train = df2[:-400]

y_test = X_test["Attrition"]
y_train = X_train["Attrition"]

X_test.pop("Attrition")
X_train.pop("Attrition")

"""**Decision Tree df2** """

clf = DecisionTreeClassifier()

if 'EmployeeNumber' in X_train.columns:
    X_train.drop("EmployeeNumber", axis=1, inplace=True)

if 'EmployeeNumber' in X_test.columns:
    X_test.drop("EmployeeNumber", axis=1, inplace=True)

clf.fit(X_train, y_train)

from sklearn.tree import plot_tree

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

# average:
#   None - results for each class separatelyo
#   'binary' - for the label selected in `pos_label`
#   'micro' - for the total number of TP, FN, FP
#   'macro' - unweighted average for each class
#   'weighted' - weighted average for each class

def calculate_metrics(target, prediction, average='macro'):
    accuracy = accuracy_score(target, prediction)
    precision = precision_score(target, prediction, average=average)
    recall = recall_score(target, prediction, average=average)
    f1 = f1_score(target, prediction, average=average)
    mislabeled = (target != prediction).sum()
    total = len(target)
    return accuracy, precision, recall, f1, mislabeled, total

def print_results(metrics, classifier_id='classifier'):
    print(f'Results for {classifier_id}')
    print('----')
    print(f'  Accuracy:  {metrics[0]}')
    print(f'  Precision: {metrics[1]}')
    print(f'  Recall:    {metrics[2]}')
    print(f'  F1 score:  {metrics[3]}')
    print(f'  Mislabeled {metrics[4]} out of {metrics[5]}')
    print('\n')
    
def plot_confusion_matrix(confusion_matrix, classes, title=None,
                          title_appendix='',
                          cmap=plt.cm.Blues):
    # plot title
    if title_appendix:
        title_appendix = f'({title_appendix})'
    if title is None:
        title = f'Confusion matrix {title_appendix}'
    
    fig, ax = plt.subplots()
    # draws CM
    img = ax.imshow(confusion_matrix, cmap=cmap)
    # adds sidebar
    ax.figure.colorbar(img, ax=ax)
    # additions to the plot
    ax.set_xticks(np.arange(confusion_matrix.shape[1]))
    ax.set_xticklabels(classes, rotation=45, ha='right', rotation_mode='anchor')
    ax.set_yticks(np.arange(confusion_matrix.shape[0]))
    ax.set_yticklabels(classes, rotation=45, ha='right', rotation_mode='anchor')
    ax.set_title(title)
    ax.set_ylabel('True label')
    ax.set_xlabel('Predicted label')
    
    # labels
    fmt = '.2f' if confusion_matrix.dtype == 'float' else 'd'
    thresh = confusion_matrix.max() / 2
    for y, row in enumerate(confusion_matrix):
        for x, cell in enumerate(row):
            ax.text(x, y, format(cell, fmt),
                    ha='center', va='center',
                    color='white' if cell > thresh else 'black')
    fig.tight_layout()
    
    return ax

def normalize_confusion_matrix(confusion_matrix):
    return confusion_matrix.astype(
        'float') / confusion_matrix.sum(
        axis=1)[np.newaxis].T

tree = DecisionTreeClassifier()

if 'EmployeeNumber' in X_train.columns:
    X_train.drop("EmployeeNumber", axis=1, inplace=True)

if 'EmployeeNumber' in X_test.columns:
    X_test.drop("EmployeeNumber", axis=1, inplace=True)

tree.fit(X_train, y_train)
y_tree = tree.predict(X_test)

print_results(calculate_metrics(y_test.values, y_tree), 'Decision Tree')
cm = confusion_matrix(y_test, y_tree)
plot_confusion_matrix(cm, ["Yes", "No"])

"""**Decision Tree df1**"""

df1["Attrition"] = df2["Attrition"]

df1.info()

df1 = df1.dropna()
df2 = df2.dropna()

X_test = df1[-400:]
X_train = df1[:-400]

y_test = X_test["Attrition"]
y_train = X_train["Attrition"]

X_test.pop("Attrition")
X_train.pop("Attrition")

clf = DecisionTreeClassifier()


if 'EmployeeNumber' in X_train.columns:
    X_train.drop("EmployeeNumber", axis=1, inplace=True)

if 'EmployeeNumber' in X_test.columns:
    X_test.drop("EmployeeNumber", axis=1, inplace=True)

clf.fit(X_train, y_train)

tree = DecisionTreeClassifier()
tree.fit(X_train, y_train)


if 'EmployeeNumber' in X_train.columns:
    X_train.drop("EmployeeNumber", axis=1, inplace=True)

if 'EmployeeNumber' in X_test.columns:
    X_test.drop("EmployeeNumber", axis=1, inplace=True)

y_tree = tree.predict(X_test)

print_results(calculate_metrics(y_test.values, y_tree), 'Decision Tree')
cm = confusion_matrix(y_test, y_tree)
plot_confusion_matrix(cm, ["Yes", "No"])

"""**Concatenated**"""

merged = pd.merge(df1.drop("Attrition", axis=1), df2, on="EmployeeNumber")

merged.info()

merged.head()

X_test = merged[-400:]
X_train = merged[:-400]

y_test = X_test["Attrition"]
y_train = X_train["Attrition"]

X_test.pop("Attrition")
X_train.pop("Attrition")

clf = DecisionTreeClassifier()


if 'EmployeeNumber' in X_train.columns:
    X_train.drop("EmployeeNumber", axis=1, inplace=True)

if 'EmployeeNumber' in X_test.columns:
    X_test.drop("EmployeeNumber", axis=1, inplace=True)

clf.fit(X_train, y_train)

tree = DecisionTreeClassifier()

if 'EmployeeNumber' in X_train.columns:
    X_train.drop("EmployeeNumber", axis=1, inplace=True)

if 'EmployeeNumber' in X_test.columns:
    X_test.drop("EmployeeNumber", axis=1, inplace=True)

tree.fit(X_train, y_train)
y_tree = tree.predict(X_test)

print_results(calculate_metrics(y_test.values, y_tree), 'Decision Tree')
cm = confusion_matrix(y_test, y_tree)
plot_confusion_matrix(cm, ["Yes", "No"])

df2 = df2[df2['YearsWithCurrManager'] > 40]
df2